{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750156, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[:100000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(x):\n",
    "    if x >=3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].apply(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = train_df.reset_index().iloc[:,1:]\n",
    "#val_df = val_df.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.sort_values(by='user',inplace=True)\n",
    "#val_df.sort_values(by='user',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df =  pd.get_dummies(df['user'],prefix='user').astype(int)\n",
    "movie_df =  pd.get_dummies(df['movie'],prefix='movie').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns= [['rating_'+str(i) for i in range(1,6041)]]\n",
    "#indexs = movie_df.index\n",
    "#data = np.zeros([600124,6040])\n",
    "#ratings = pd.DataFrame(columns=columns,data=data)\n",
    "#ratings.index = indexs\n",
    "#ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = user_df.merge(movie_df,left_index=True,right_index=True)\n",
    "Y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "99995    0\n",
       "99996    0\n",
       "99997    1\n",
       "99998    1\n",
       "99999    0\n",
       "Name: rating, Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_sparse = scipy.sparse.csr_matrix(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = train_df['rating']\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.shape)\n",
    "#print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_df =  pd.get_dummies(val_df['user'],prefix='user').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_df =  pd.get_dummies(val_df['movie'],prefix='movie').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = user_df.merge(movie_df,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = val_df['rating']\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "k = 10\n",
    "batch_size = 128\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>895537</td>\n",
       "      <td>5412</td>\n",
       "      <td>2683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>899740</td>\n",
       "      <td>5440</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55688</td>\n",
       "      <td>368</td>\n",
       "      <td>3717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63728</td>\n",
       "      <td>425</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>822012</td>\n",
       "      <td>4942</td>\n",
       "      <td>3697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  user  movie\n",
       "0  895537  5412   2683\n",
       "1  899740  5440    904\n",
       "2   55688   368   3717\n",
       "3   63728   425   1721\n",
       "4  822012  4942   3697"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df =  pd.get_dummies(test['user'],prefix='user').astype(int)\n",
    "movie_df =  pd.get_dummies(test['movie'],prefix='movie').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = user_df.merge(movie_df,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class FM(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FM, self).__init__()\n",
    "\n",
    "        self.w_0 = tf.Variable([0.0])\n",
    "        self.w = tf.Variable(tf.zeros([p]))\n",
    "        self.V = tf.Variable(tf.random.normal(shape=(p, k)))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        linear_terms = tf.reduce_sum(tf.math.multiply(self.w, inputs), axis=1)\n",
    "\n",
    "        interactions = 0.5 * tf.reduce_sum(\n",
    "            tf.math.pow(tf.matmul(inputs, self.V), 2)\n",
    "            - tf.matmul(tf.math.pow(inputs, 2), tf.math.pow(self.V, 2)),\n",
    "            1,\n",
    "            keepdims=False\n",
    "        )\n",
    "\n",
    "        y_hat = tf.math.sigmoid(self.w_0 + linear_terms + interactions)\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward\n",
    "def train_on_batch(model, optimizer, accuracy, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs)\n",
    "        loss = tf.keras.losses.binary_crossentropy(from_logits=False,\n",
    "                                                   y_true=targets,\n",
    "                                                   y_pred=y_pred)\n",
    "    \n",
    "    # loss를 모델의 파라미터로 편미분하여 gradients를 구한다.\n",
    "    grads = tape.gradient(target=loss, sources=model.trainable_variables)\n",
    "\n",
    "    # apply_gradients()를 통해 processed gradients를 적용한다.\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # accuracy: update할 때마다 정확도는 누적되어 계산된다.\n",
    "    accuracy.update_state(targets, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 이전의 train 함수에서 호출 부분을 수정하여 모델을 평가하도록 변경합니다.\n",
    "# 반복 학습 함수\n",
    "def train(epochs):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y)\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(X_train, tf.float32), tf.cast(Y_train, tf.float32))).shuffle(500).batch(8)\n",
    "\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.cast(X_test, tf.float32), tf.cast(Y_test, tf.float32))).shuffle(200).batch(8)\n",
    "\n",
    "    model = FM()\n",
    "    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.01)\n",
    "    accuracy = tf.keras.metrics.BinaryAccuracy(threshold=0.5)\n",
    "    loss_history = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "      for x, y in train_ds:\n",
    "          loss = train_on_batch(model, optimizer, accuracy, x, y)\n",
    "          loss_history.append(loss)\n",
    "\n",
    "      if i % 2== 0:\n",
    "          print(\"스텝 {:03d}에서 누적 평균 손실: {:.4f}\".format(i, np.mean(loss_history)))\n",
    "          print(\"스텝 {:03d}에서 누적 정확도: {:.4f}\".format(i, accuracy.result().numpy()))\n",
    "\n",
    "\n",
    "    test_accuracy = tf.keras.metrics.BinaryAccuracy(threshold=0.5)\n",
    "    for x, y in test_ds:\n",
    "        y_pred = model(x)\n",
    "        test_accuracy.update_state(y, y_pred)\n",
    "\n",
    "    print(\"테스트 정확도: {:.4f}\".format(test_accuracy.result().numpy()))\n",
    "    print('\\n')\n",
    "    print('평가 시작\\n')\n",
    "    rating =[]\n",
    "    eval = tf.data.Dataset.from_tensor_slices(tf.cast(X_test, tf.float32)).shuffle(200).batch(8)\n",
    "    for x in eval:\n",
    "        try:\n",
    "            y_pred = model(x)\n",
    "            rating.append(y_pred)\n",
    "        except:\n",
    "            rating.append(1)\n",
    "\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스텝 000에서 누적 평균 손실: 0.9286\n",
      "스텝 000에서 누적 정확도: 0.7270\n",
      "스텝 002에서 누적 평균 손실: 0.8972\n",
      "스텝 002에서 누적 정확도: 0.7444\n",
      "스텝 004에서 누적 평균 손실: 0.8810\n",
      "스텝 004에서 누적 정확도: 0.7490\n",
      "스텝 006에서 누적 평균 손실: 0.8674\n",
      "스텝 006에서 누적 정확도: 0.7518\n",
      "스텝 008에서 누적 평균 손실: 0.8549\n",
      "스텝 008에서 누적 정확도: 0.7539\n",
      "테스트 정확도: 0.7545\n",
      "\n",
      "\n",
      "평가 시작\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fm = train(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval 부분에서 평가를 진행하지 못함..ㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = tf.keras.metrics.BinaryAccuracy(threshold=0.5)\n",
    "test_accuracy.update_state([0.91065073, 0.87210613, 0.45799118, 0.99571574, 0.12938377,\n",
    "        0.7050097 , 0.9852476 , 0.2945354 ], [0.91065073, 0.87210613, 0.45799118, 0.99571574, 0.12938377,\n",
    "        0.7050097 , 0.9852476 , 0.2945354 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(pred, y):\n",
    "    return np.log(np.exp(-pred * y) + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update gradients\n",
    "def sgd(X, y, n_samples, n_features,\n",
    "                w0, w, v, n_factors, learning_rate, reg_w, reg_v):\n",
    "    data = X.data\n",
    "    indptr = X.indptr\n",
    "    indices = X.indices\n",
    "    loss = 0.0\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        pred, summed = predict(X, w0, w, v, n_factors, i)\n",
    "        \n",
    "        # calculate loss and its gradient\n",
    "        loss += log_loss(pred, y[i])\n",
    "        loss_gradient = -y[i] / (np.exp(y[i] * pred) + 1.0)\n",
    "    \n",
    "        # update bias/intercept term\n",
    "        w0 -= learning_rate * loss_gradient \n",
    "\n",
    "        # update weight\n",
    "        for index in range(indptr[i], indptr[i + 1]):\n",
    "            feature = indices[index]\n",
    "            w[feature] -= learning_rate * (loss_gradient * data[index] + 2 * reg_w * w[feature])\n",
    "\n",
    "        # update factor\n",
    "        for factor in range(n_factors):\n",
    "            for index in range(indptr[i], indptr[i + 1]):\n",
    "                feature = indices[index]\n",
    "                term = summed[factor] - v[factor, feature] * data[index]\n",
    "                v_gradient = loss_gradient * data[index] * term\n",
    "                v[factor, feature] -= learning_rate * (v_gradient + 2 * reg_v * v[factor, feature])\n",
    "    \n",
    "    loss /= n_samples\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w0, w, v, n_factors, i):\n",
    "    data = X.data\n",
    "    indptr = X.indptr\n",
    "    indices = X.indices\n",
    "    \"\"\"predicting a single instance\"\"\"\n",
    "    summed = np.zeros(n_factors)\n",
    "    summed_squared = np.zeros(n_factors)\n",
    "\n",
    "    # linear output w * x\n",
    "    pred = w0\n",
    "    for index in range(indptr[i], indptr[i + 1]):\n",
    "        feature = indices[index]\n",
    "        pred += w[feature] * data[index]\n",
    "\n",
    "    # factor output\n",
    "    for factor in range(n_factors):\n",
    "        for index in range(indptr[i], indptr[i + 1]):\n",
    "            feature = indices[index]\n",
    "            term = v[factor, feature] * data[index]\n",
    "            summed[factor] += term\n",
    "            summed_squared[factor] += term * term\n",
    "            \n",
    "        \n",
    "        pred += 0.5 * (summed[factor] * summed[factor] - summed_squared[factor])\n",
    "\n",
    "    # gradient update할 때, summed는 독립이므로 re-use 가능\n",
    "    return pred, summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Factorization Machine\n",
    "# X -> sparse csr_matrix, y -> label\n",
    "def fit(X, y, config):\n",
    "    epochs = config['num_epochs']\n",
    "    num_factors = config['num_factors']\n",
    "    learning_rate = config['learning_rate']\n",
    "    reg_weights = config['reg_weights']\n",
    "    reg_features = config['reg_features']\n",
    "\n",
    "    num_samples, num_features = X.shape\n",
    "    weights = np.zeros(num_features) # -> w\n",
    "    global_bias = 0.0 # -> w0\n",
    "    \n",
    "    # latent factors for all features -> v\n",
    "    feature_factors = np.random.normal(size = (num_factors, num_features))\n",
    "\n",
    "    epoch_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #loss 값이 계속 떨어지면서 학습이 되는지 확인\n",
    "        loss = sgd(X, y, num_samples, num_features,\n",
    "                            global_bias, weights,\n",
    "                            feature_factors, num_factors,\n",
    "                            learning_rate, reg_weights, reg_features)\n",
    "        print(f'[epoch: {epoch+1}], loss: {loss}')\n",
    "\n",
    "        epoch_loss.append(loss)\n",
    "      \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = {\n",
    "#    \"num_epochs\": 10,\n",
    "#    \"num_factors\": 10,\n",
    "#    \"learning_rate\": 0.1,\n",
    "#    \"reg_weights\": 0.01,\n",
    "#    \"reg_features\": 0.01\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch_loss = fit(X_train_sparse, y_train.values, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(epoch_loss)\n",
    "#plt.title('Loss per epoch')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
